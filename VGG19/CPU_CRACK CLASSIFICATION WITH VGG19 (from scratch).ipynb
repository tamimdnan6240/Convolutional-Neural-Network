{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85dae658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tamim\\anaconda3\\envs\\DeepCrack\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1e1cebb3a30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f826fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available = lambda : False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb94d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a577abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Path('./outputs')\n",
    "if not outputs.is_dir():\n",
    "    outputs.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a6220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for saving weights of trained model\n",
    "def save_model(epochs, model, optimizer, criterion, name='model', descr=''):\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                'descr': descr,\n",
    "                }, f'outputs/{name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5e7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ce29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 32\n",
    "num_classes = 7\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35756985",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cf5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "train_folder = ImageFolder(\"D:\\\\SPRING 2023\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)_training\", transform=train_trans , )\n",
    "test_folder = ImageFolder(\"D:\\\\SPRING 2023\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)_validation\", transform=valid_trans , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ebcede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_folder.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d9c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alligator Cracks',\n",
       " 'Delamination',\n",
       " 'Longitudinal Cracks',\n",
       " 'Transverse Cracks']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_name = train_folder.classes\n",
    "classes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556090d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data on batches\n",
    "train_loader = torch.utils.data.DataLoader(train_folder, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_folder, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ce6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the first batch\n",
    "data, labels = next(iter(train_loader))\n",
    "# data, labels = data.cpu(), labels.cpu() ## Solution: https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748cf6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90956eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "767c0837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc75147",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3456c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def Conv3X3(in_, out):\n",
    "    return torch.nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = Conv3X3(in_, out)\n",
    "        self.activation = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, nn):\n",
    "        super(Down,self).__init__()\n",
    "        self.nn = nn\n",
    "        self.maxpool_with_argmax = torch.nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        down = self.nn(inputs)\n",
    "        unpooled_shape = down.size()\n",
    "        outputs, indices = self.maxpool_with_argmax(down)\n",
    "        return outputs, down, indices, unpooled_shape\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "        self.unpool=torch.nn.MaxUnpool2d(2,2)\n",
    "\n",
    "    def forward(self,inputs,indices,output_shape):\n",
    "        outputs = self.unpool(inputs, indices=indices, output_size=output_shape)\n",
    "        outputs = self.nn(outputs)\n",
    "        return outputs\n",
    "\n",
    "class Fuse(nn.Module):\n",
    "\n",
    "    def __init__(self, nn, scale):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "        self.scale = scale\n",
    "        self.conv = Conv3X3(64,1)\n",
    "\n",
    "    def forward(self,down_inp,up_inp):\n",
    "        outputs = torch.cat([down_inp, up_inp], 1)\n",
    "        outputs = F.interpolate(outputs, scale_factor=self.scale, mode='bilinear')\n",
    "        outputs = self.nn(outputs)\n",
    "\n",
    "        return self.conv(outputs)\n",
    "\n",
    "\n",
    "\n",
    "class DeepCrack(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(DeepCrack, self).__init__()\n",
    "\n",
    "        self.down1 = Down(torch.nn.Sequential(\n",
    "            ConvRelu(3,64),\n",
    "            ConvRelu(64,64),\n",
    "        ))\n",
    "\n",
    "        self.down2 = Down(torch.nn.Sequential(\n",
    "            ConvRelu(64,128),\n",
    "            ConvRelu(128,128),\n",
    "        ))\n",
    "\n",
    "        self.down3 = Down(torch.nn.Sequential(\n",
    "            ConvRelu(128,256),\n",
    "            ConvRelu(256,256),\n",
    "            ConvRelu(256,256),\n",
    "        ))\n",
    "\n",
    "        self.down4 = Down(torch.nn.Sequential(\n",
    "            ConvRelu(256, 512),\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "        ))\n",
    "\n",
    "        self.down5 = Down(torch.nn.Sequential(\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "        ))\n",
    "\n",
    "        self.up1 = Up(torch.nn.Sequential(\n",
    "            ConvRelu(64, 64),\n",
    "            ConvRelu(64, 64),\n",
    "        ))\n",
    "\n",
    "        self.up2 = Up(torch.nn.Sequential(\n",
    "            ConvRelu(128, 128),\n",
    "            ConvRelu(128, 64),\n",
    "        ))\n",
    "\n",
    "        self.up3 = Up(torch.nn.Sequential(\n",
    "            ConvRelu(256, 256),\n",
    "            ConvRelu(256, 256),\n",
    "            ConvRelu(256, 128),\n",
    "        ))\n",
    "\n",
    "        self.up4 = Up(torch.nn.Sequential(\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 256),\n",
    "        ))\n",
    "\n",
    "        self.up5 = Up(torch.nn.Sequential(\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "            ConvRelu(512, 512),\n",
    "        ))\n",
    "\n",
    "        self.fuse5 = Fuse(ConvRelu(512 + 512, 64), scale=16)\n",
    "        self.fuse4 = Fuse(ConvRelu(512 + 256, 64), scale=8)\n",
    "        self.fuse3 = Fuse(ConvRelu(256 + 128, 64), scale=4)\n",
    "        self.fuse2 = Fuse(ConvRelu(128 + 64, 64), scale=2)\n",
    "        self.fuse1 = Fuse(ConvRelu(64 + 64, 64), scale=1)\n",
    "\n",
    "        self.final = Conv3X3(5,1)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "\n",
    "        # encoder part\n",
    "        out, down1, indices_1, unpool_shape1 = self.down1(inputs)\n",
    "        out, down2, indices_2, unpool_shape2 = self.down2(out)\n",
    "        out, down3, indices_3, unpool_shape3 = self.down3(out)\n",
    "        out, down4, indices_4, unpool_shape4 = self.down4(out)\n",
    "        out, down5, indices_5, unpool_shape5 = self.down5(out)\n",
    "\n",
    "        # decoder part\n",
    "        up5 = self.up5(out, indices=indices_5, output_shape=unpool_shape5)\n",
    "        up4 = self.up4(up5, indices=indices_4, output_shape=unpool_shape4)\n",
    "        up3 = self.up3(up4, indices=indices_3, output_shape=unpool_shape3)\n",
    "        up2 = self.up2(up3, indices=indices_2, output_shape=unpool_shape2)\n",
    "        up1 = self.up1(up2, indices=indices_1, output_shape=unpool_shape1)\n",
    "\n",
    "        fuse5 = self.fuse5(down_inp=down5,up_inp=up5)\n",
    "        fuse4 = self.fuse4(down_inp=down4, up_inp=up4)\n",
    "        fuse3 = self.fuse3(down_inp=down3, up_inp=up3)\n",
    "        fuse2 = self.fuse2(down_inp=down2, up_inp=up2)\n",
    "        fuse1 = self.fuse1(down_inp=down1, up_inp=up1)\n",
    "\n",
    "        output = self.final(torch.cat([fuse5,fuse4,fuse3,fuse2,fuse1],1))\n",
    "\n",
    "        return output, fuse5, fuse4, fuse3, fuse2, fuse1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inp = torch.randn((1,3,512,512))\n",
    "\n",
    "    model = DeepCrack()\n",
    "\n",
    "    out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb167ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining model optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "def mean(l: list):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies): \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].plot(train_losses, label='train_losses')\n",
    "    axes[0].plot(valid_losses, label='valid_losses')\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[0].legend()\n",
    "    plt.savefig(\"Loss in combination 1.JPG\")\n",
    "    \n",
    "    axes[1].plot(train_accuracies, label='train_losses')\n",
    "    axes[1].plot(valid_accuracies, label='valid_losses')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.savefig(\"Accuracy in combination 1.JPG\")\n",
    "    \n",
    "def validate(model, valid_data, loss_fn):\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(valid_data, leave=False):\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "            valid_accuracies.append(((preds == y_batch).sum() / len(preds)).item())\n",
    "    return mean(valid_losses), mean(valid_accuracies)\n",
    "    \n",
    "\n",
    "def train(model, train_data, valid_data, loss_fn, opt, epoches):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(train_data, leave=False):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch,)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            train_acc.append(((pred == y_batch).sum() / len(pred)).item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        valid_loss, valid_accuracy = validate(model, valid_data, loss_fn)\n",
    "\n",
    "        train_accuracies.append(mean(train_acc))\n",
    "        train_losses.append(mean(train_loss))\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'epoch: {epoch}: train_loss: {mean(train_losses)}, train_acc: {mean(train_acc)}, val_loss: {valid_loss}, val_acc: {valid_accuracy}')\n",
    "    plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies)\n",
    "    return model, train_losses, train_accuracies, valid_losses, valid_accuracies\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "model, train_losses, train_accuracies, valid_losses, valid_accuracies = train(model, train_loader, val_loader, loss_fn, opt, epoches=num_epochs)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "## loss calculation\n",
    "\n",
    "valid_loss, valid_acc = validate(model, test_loader, loss_fn)\n",
    "\n",
    "print(valid_loss, valid_acc)\n",
    "\n",
    "##Testing\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "#Save model\n",
    "PATH = './VGG19New.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "\n",
    "##Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "\n",
    "# prepare to count predictions for each class on iphone image data\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed because we already trained\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
