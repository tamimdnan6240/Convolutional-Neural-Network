{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc815f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from random import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "outputs = Path('./outputs')\n",
    "if not outputs.is_dir():\n",
    "    outputs.mkdir()\n",
    "    \n",
    "# function for saving weights of trained model\n",
    "def save_model(epochs, model, optimizer, criterion, name='model', descr=''):\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                'descr': descr,\n",
    "                }, f'outputs/{name}.pth')\n",
    "    \n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.RandomRotation(degrees=(30, 70)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "train_folder = ImageFolder(\"./Data_Structure(Annotated)\", transform=train_trans , )\n",
    "test_folder = ImageFolder(\"./Data_Structure(Annotated)\", transform=valid_trans , )\n",
    "\n",
    "len(train_folder.classes)\n",
    "\n",
    "classes_name = train_folder.classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_folder, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_folder, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "data, labels = next(iter(train_loader))\n",
    "\n",
    "data = torch.tensor(data)\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "model = models.vgg19(pretrained=True)\n",
    "model\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, 7) # original model has outputs for 1000 classes. \n",
    "# But there are only 75 classes so we have to change output layer\n",
    "\n",
    "# Freezing all layers except last 15\n",
    "for param in list(model.parameters())[:-15]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "## Defining model optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def mean(l: list):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies): \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].plot(train_losses, label='train_losses')\n",
    "    axes[0].plot(valid_losses, label='valid_losses')\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(train_accuracies, label='train_losses')\n",
    "    axes[1].plot(valid_accuracies, label='valid_losses')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    \n",
    "def validate(model, valid_data, loss_fn):\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(valid_data, leave=False):\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "            valid_accuracies.append(((preds == y_batch).sum() / len(preds)).item())\n",
    "    return mean(valid_losses), mean(valid_accuracies)\n",
    "    \n",
    "\n",
    "def train(model, train_data, valid_data, loss_fn, opt, epoches):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(train_data, leave=False):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch,)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            train_acc.append(((pred == y_batch).sum() / len(pred)).item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        valid_loss, valid_accuracy = validate(model, valid_data, loss_fn)\n",
    "\n",
    "        train_accuracies.append(mean(train_acc))\n",
    "        train_losses.append(mean(train_loss))\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'epoch: {epoch}: train_loss: {mean(train_losses)}, train_acc: {mean(train_acc)}, val_loss: {valid_loss}, val_acc: {valid_accuracy}')\n",
    "    plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies)\n",
    "    return model, train_losses, train_accuracies, valid_losses, valid_accuracies\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "model, train_losses, train_accuracies, valid_losses, valid_accuracies = train(model, train_loader, test_loader, loss_fn, opt, epoches=num_epochs)\n",
    "\n",
    "save_model(25, model, opt, loss_fn, 'vgg19', descr='15 unfrozen layers; 1e-4 lr')\n",
    "\n",
    "valid_loss, valid_acc = validate(model, test_loader, loss_fn)\n",
    "\n",
    "print(valid_loss, valid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
