{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F     F     G     F     F     F     F     F     F     F     G     G     F     F     G     F     G     G     G     G     G     F     F     G     F     F     G     G     F     F     G     G    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/304 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/304 [00:33<2:49:21, 33.54s/it]\u001b[A\n",
      "  1%|          | 2/304 [01:06<2:46:50, 33.15s/it]\u001b[A\n",
      "  1%|          | 3/304 [01:39<2:45:28, 32.98s/it]\u001b[A\n",
      "  1%|▏         | 4/304 [02:11<2:44:31, 32.91s/it]\u001b[A\n",
      "  2%|▏         | 5/304 [02:44<2:43:24, 32.79s/it]\u001b[A\n",
      "  2%|▏         | 6/304 [03:18<2:45:32, 33.33s/it]\u001b[A\n",
      "  2%|▏         | 7/304 [03:55<2:50:30, 34.45s/it]\u001b[A\n",
      "  3%|▎         | 8/304 [04:30<2:50:59, 34.66s/it]\u001b[A\n",
      "  3%|▎         | 9/304 [05:05<2:50:55, 34.77s/it]\u001b[A\n",
      "  3%|▎         | 10/304 [05:41<2:52:23, 35.18s/it]\u001b[A\n",
      "  4%|▎         | 11/304 [06:17<2:53:07, 35.45s/it]\u001b[A\n",
      "  4%|▍         | 12/304 [06:54<2:54:28, 35.85s/it]\u001b[A\n",
      "  4%|▍         | 13/304 [07:31<2:54:50, 36.05s/it]\u001b[A\n",
      "  5%|▍         | 14/304 [08:08<2:55:38, 36.34s/it]\u001b[A\n",
      "  5%|▍         | 15/304 [08:44<2:54:53, 36.31s/it]\u001b[A\n",
      "  5%|▌         | 16/304 [09:21<2:54:55, 36.44s/it]\u001b[A\n",
      "  6%|▌         | 17/304 [09:57<2:53:48, 36.34s/it]\u001b[A\n",
      "  6%|▌         | 18/304 [10:32<2:51:52, 36.06s/it]\u001b[A\n",
      "  6%|▋         | 19/304 [11:08<2:50:49, 35.96s/it]\u001b[A\n",
      "  7%|▋         | 20/304 [11:44<2:50:23, 36.00s/it]\u001b[A\n",
      "  7%|▋         | 21/304 [12:21<2:50:30, 36.15s/it]\u001b[A\n",
      "  7%|▋         | 22/304 [12:57<2:50:53, 36.36s/it]\u001b[A\n",
      "  8%|▊         | 23/304 [13:38<2:56:03, 37.59s/it]\u001b[A\n",
      "  8%|▊         | 24/304 [14:24<3:07:55, 40.27s/it]\u001b[A\n",
      "  8%|▊         | 25/304 [15:23<3:32:15, 45.65s/it]\u001b[A\n",
      "  9%|▊         | 26/304 [16:31<4:03:43, 52.60s/it]\u001b[A\n",
      "  9%|▉         | 27/304 [17:43<4:28:43, 58.21s/it]\u001b[A\n",
      "  9%|▉         | 28/304 [18:51<4:41:57, 61.30s/it]\u001b[A\n",
      " 10%|▉         | 29/304 [19:55<4:44:05, 61.98s/it]\u001b[A\n",
      " 10%|▉         | 30/304 [20:55<4:40:11, 61.36s/it]\u001b[A\n",
      " 10%|█         | 31/304 [21:50<4:30:53, 59.54s/it]\u001b[A\n",
      " 11%|█         | 32/304 [22:46<4:24:29, 58.34s/it]\u001b[A\n",
      " 11%|█         | 33/304 [23:40<4:18:29, 57.23s/it]\u001b[A\n",
      " 11%|█         | 34/304 [24:30<4:07:52, 55.08s/it]\u001b[A\n",
      " 12%|█▏        | 35/304 [25:49<4:39:25, 62.32s/it]\u001b[A\n",
      " 12%|█▏        | 36/304 [41:44<24:33:17, 329.84s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from random import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "  \n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    plt.savefig('labels.JPG')\n",
    "    \n",
    "    \n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 2\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "        )\n",
    "])\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets import ImageFolder\n",
    "train_folder = ImageFolder(\"D:\\SPRING 2023\\CyberGIS and Big Data_INES_8090_G02\\Class Project\\FINAL\\GeoTIFF\", transform=train_trans , )\n",
    "val_folder = ImageFolder(\"D:\\SPRING 2023\\CyberGIS and Big Data_INES_8090_G02\\Class Project\\FINAL\\GeoTIFF\", transform=train_trans , )\n",
    "test_folder= ImageFolder(\"D:\\SPRING 2023\\CyberGIS and Big Data_INES_8090_G02\\Class Project\\FINAL\\GeoTIFF\", transform=test_trans, )\n",
    "\n",
    "\n",
    "len(train_folder.classes)\n",
    "\n",
    "classes = (train_folder.classes)\n",
    "\n",
    "# Splitting data on batches\n",
    "train_loader = torch.utils.data.DataLoader(train_folder, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_folder, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_folder, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "## https://discuss.pytorch.org/t/how-to-modify-a-pretrained-model/60509/12\n",
    "def replace_layers(model, old, new):\n",
    "    for n, module in model.named_children():\n",
    "        if len(list(module.children())) > 0:\n",
    "            ## compound module, go inside it\n",
    "            replace_layers(module, old, new)\n",
    "            \n",
    "        if isinstance(module, old):\n",
    "            ## simple module\n",
    "            setattr(model, n, new)\n",
    "\n",
    "replace_layers(model.features, nn.ReLU, nn.LeakyReLU())\n",
    "replace_layers(model.classifier, nn.ReLU, nn.Softmax())\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, 7) # original model has outputs for 1000 classes. \n",
    "\n",
    "\n",
    "# Freezing all layers except last 15\n",
    "#for param in list(model.parameters())[:-15]:\n",
    " #   param.requires_grad = False\n",
    "\n",
    "    \n",
    "## Defining model optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def mean(l: list):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies): \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].plot(train_losses, label='train_losses')\n",
    "    axes[0].plot(valid_losses, label='valid_losses')\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[0].legend()\n",
    "    plt.savefig(\"Loss in combination 1.JPG\")\n",
    "    \n",
    "    axes[1].plot(train_accuracies, label='train_losses')\n",
    "    axes[1].plot(valid_accuracies, label='valid_losses')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.savefig(\"Accuracy in combination 1.JPG\")\n",
    "    \n",
    "def validate(model, valid_data, loss_fn):\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(valid_data, leave=False):\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "            valid_accuracies.append(((preds == y_batch).sum() / len(preds)).item())\n",
    "    return mean(valid_losses), mean(valid_accuracies)\n",
    "    \n",
    "\n",
    "def train(model, train_data, valid_data, loss_fn, opt, epoches):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(train_data, leave=False):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch,)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            train_acc.append(((pred == y_batch).sum() / len(pred)).item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        valid_loss, valid_accuracy = validate(model, valid_data, loss_fn)\n",
    "\n",
    "        train_accuracies.append(mean(train_acc))\n",
    "        train_losses.append(mean(train_loss))\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'epoch: {epoch}: train_loss: {mean(train_losses)}, train_acc: {mean(train_acc)}, val_loss: {valid_loss}, val_acc: {valid_accuracy}')\n",
    "    plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies)\n",
    "    return model, train_losses, train_accuracies, valid_losses, valid_accuracies\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "model, train_losses, train_accuracies, valid_losses, valid_accuracies = train(model, train_loader, val_loader, loss_fn, opt, epoches=num_epochs)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "## loss calculation\n",
    "\n",
    "valid_loss, valid_acc = validate(model, test_loader, loss_fn)\n",
    "\n",
    "print(valid_loss, valid_acc)\n",
    "\n",
    "##Testing\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "#Save model\n",
    "PATH = './VGG19New.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "\n",
    "##Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "\n",
    "# prepare to count predictions for each class on iphone image data\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed because we already trained\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986599a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
