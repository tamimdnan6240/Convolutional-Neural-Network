{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from random import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "  \n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    plt.savefig('labels.JPG')\n",
    "    \n",
    "    \n",
    "batch_size = 32\n",
    "num_classes = 7\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "        )\n",
    "])\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets import ImageFolder\n",
    "train_folder = ImageFolder(\"D:\\\\SPRING 2023\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)_training\", transform=train_trans , )\n",
    "val_folder = ImageFolder(\"D:\\\\SPRING 2023\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)_validation\", transform=train_trans , )\n",
    "test_folder= ImageFolder(\"D:\\\\SPRING 2023\\\\MS_Thesis\\\\MASTER'S THESIS\\\\DATA_iPhone_13_Pro_Max\", transform=test_trans, )\n",
    "\n",
    "\n",
    "len(train_folder.classes)\n",
    "\n",
    "classes = ('Alligator Cracks', 'Delamination', 'Longitudinal Cracks', 'Transverse Cracks')\n",
    "\n",
    "# Splitting data on batches\n",
    "train_loader = torch.utils.data.DataLoader(train_folder, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_folder, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_folder, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "## https://discuss.pytorch.org/t/how-to-modify-a-pretrained-model/60509/12\n",
    "def replace_layers(model, old, new):\n",
    "    for n, module in model.named_children():\n",
    "        if len(list(module.children())) > 0:\n",
    "            ## compound module, go inside it\n",
    "            replace_layers(module, old, new)\n",
    "            \n",
    "        if isinstance(module, old):\n",
    "            ## simple module\n",
    "            setattr(model, n, new)\n",
    "\n",
    "#replace_layers(model.features, nn.ReLU, nn.Tanh())\n",
    "replace_layers(model.classifier, nn.ReLU, nn.Softmax())\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, 7) # original model has outputs for 1000 classes. \n",
    "\n",
    "\n",
    "# Freezing all layers except last 15\n",
    "#for param in list(model.parameters())[:-15]:\n",
    " #   param.requires_grad = False\n",
    "\n",
    "    \n",
    "## Defining model optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "def mean(l: list):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies): \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].plot(train_losses, label='train_losses')\n",
    "    axes[0].plot(valid_losses, label='valid_losses')\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[0].legend()\n",
    "    plt.savefig(\"Loss in combination 1.JPG\")\n",
    "    \n",
    "    axes[1].plot(train_accuracies, label='train_losses')\n",
    "    axes[1].plot(valid_accuracies, label='valid_losses')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.savefig(\"Accuracy in combination 1.JPG\")\n",
    "    \n",
    "def validate(model, valid_data, loss_fn):\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(valid_data, leave=False):\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "            valid_accuracies.append(((preds == y_batch).sum() / len(preds)).item())\n",
    "    return mean(valid_losses), mean(valid_accuracies)\n",
    "    \n",
    "\n",
    "def train(model, train_data, valid_data, loss_fn, opt, epoches):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(train_data, leave=False):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            X_batch, y_batch = X_batch.float(), y_batch.long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch,)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            train_acc.append(((pred == y_batch).sum() / len(pred)).item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        valid_loss, valid_accuracy = validate(model, valid_data, loss_fn)\n",
    "\n",
    "        train_accuracies.append(mean(train_acc))\n",
    "        train_losses.append(mean(train_loss))\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'epoch: {epoch}: train_loss: {mean(train_losses)}, train_acc: {mean(train_acc)}, val_loss: {valid_loss}, val_acc: {valid_accuracy}')\n",
    "    plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies)\n",
    "    return model, train_losses, train_accuracies, valid_losses, valid_accuracies\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "model, train_losses, train_accuracies, valid_losses, valid_accuracies = train(model, train_loader, val_loader, loss_fn, opt, epoches=num_epochs)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "## loss calculation\n",
    "\n",
    "valid_loss, valid_acc = validate(model, test_loader, loss_fn)\n",
    "\n",
    "print(valid_loss, valid_acc)\n",
    "\n",
    "##Testing\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# resource: #https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "#Save model\n",
    "PATH = './VGG19New.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "\n",
    "##Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "\n",
    "# prepare to count predictions for each class on iphone image data\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed because we already trained\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3e588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
