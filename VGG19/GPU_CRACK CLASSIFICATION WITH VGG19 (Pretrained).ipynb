{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a534066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x27bb6b36040>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "from random import *\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42de825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear cuda memory\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "208cf704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Engaging GPU\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5d291d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24841e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Butterfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e2e0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Path('./outputs')\n",
    "if not outputs.is_dir():\n",
    "    outputs.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53adac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d10ab641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for saving weights of trained model\n",
    "def save_model(epochs, model, optimizer, criterion, name='model', descr=''):\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                'descr': descr,\n",
    "                }, f'outputs/{name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3225f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf35815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce268a2c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deca0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 16\n",
    "num_classes = 7\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f94adf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.RandomRotation(degrees=(30, 70)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f76a98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "train_folder = ImageFolder(\"D:\\\\FALL 2022\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)\", transform=train_trans , )\n",
    "test_folder = ImageFolder(\"D:\\\\FALL 2022\\\\MS_Thesis\\\\MASTER'S THESIS\\\\EdmCrack600\\\\Data_Structure(Annotated)\", transform=valid_trans , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb116634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_folder.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cab4f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLIGATOR ( Fatigue plus Longitudinal Cracks on Wheel Paths',\n",
       " 'BLEEDING_',\n",
       " 'DELAMINATION',\n",
       " 'LONGITUDINAL LANE JOINT CRACKING_',\n",
       " 'LONGITUDINAL OUTSIDE OF THE WHEEL PATHS_',\n",
       " 'Raveling',\n",
       " 'Transverse Crack']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdd8343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLIGATOR ( Fatigue plus Longitudinal Cracks on Wheel Paths',\n",
       " 'BLEEDING_',\n",
       " 'DELAMINATION',\n",
       " 'LONGITUDINAL LANE JOINT CRACKING_',\n",
       " 'LONGITUDINAL OUTSIDE OF THE WHEEL PATHS_',\n",
       " 'Raveling',\n",
       " 'Transverse Crack']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_name = train_folder.classes\n",
    "classes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87cbc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data on batches\n",
    "train_loader = torch.utils.data.DataLoader(train_folder, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_folder, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d2316c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the first batch\n",
    "data, labels = next(iter(train_loader))\n",
    "# data, labels = data.cpu(), labels.cpu() ## Solution: https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab228709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d54eeeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "696905a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9c0e8",
   "metadata": {},
   "source": [
    "1. The input of a Pytorch Neural Network is of type [BATCH_SIZE] * [CHANNEL_NUMBER] * [HEIGHT] * [WIDTH]\n",
    "\n",
    "2. 1×3×32×32 meaning that you have 1 image with 3 channels (RGB) with height 32 and width 32\n",
    "\n",
    "3. . The formular of convolution is ((W - F + 2P)/ S )+1 and ((H - F + 2P)/ S )+1\n",
    "\n",
    "4. W =  WIDTH, F  = FILTER_SIZE, P = PADDIND, S = STRIDE\n",
    "\n",
    "with our input 1×3×32×32 after applying conv1 W will be 28 and H will be 28 and also applying (2,2) pooling halves the WIDTH and HEIGTH and We have 6 feature maps. So after the first con2d and pooling we end up with an image of dimension\n",
    "1 * 6 * 14 * 14. Similaly for the second conv2d and pooling we will end up with an image of dimension 1 * 16 * 5 * 5 . Finally since we need a column vector for the first fc layer we should unroll our vector which is 16×5×5 = 400\n",
    "\n",
    "https://discuss.pytorch.org/t/input-size-of-fc-layer-in-tutorial/14644\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a217f83",
   "metadata": {},
   "source": [
    "## Here, the given relationship between the kernel size and padding is that padding = (kernel size - 1) / 2. Max pooling with kernel_size = stride = 2 will decrease the width/height by a factor of 2 (rounded down if input shape is not even).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a027099",
   "metadata": {},
   "source": [
    "## Load VGG 19 Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd2e4882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = models.vgg19(pretrained=True).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebad3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68d0db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(4096, 7).to(device) # original model has outputs for 1000 classes. \n",
    "# But there are only 75 classes so we have to change output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1932dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all layers except last 15\n",
    "for param in list(model.parameters())[:-15]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00fca1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining model optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1782e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-18          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-19          [-1, 256, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-25          [-1, 512, 28, 28]               0\n",
      "           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-27          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-32          [-1, 512, 14, 14]               0\n",
      "           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-34          [-1, 512, 14, 14]               0\n",
      "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-36          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-37            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n",
      "           Linear-39                 [-1, 4096]     102,764,544\n",
      "             ReLU-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "           Linear-42                 [-1, 4096]      16,781,312\n",
      "             ReLU-43                 [-1, 4096]               0\n",
      "          Dropout-44                 [-1, 4096]               0\n",
      "           Linear-45                    [-1, 7]          28,679\n",
      "================================================================\n",
      "Total params: 139,598,919\n",
      "Trainable params: 129,013,767\n",
      "Non-trainable params: 10,585,152\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 238.68\n",
      "Params size (MB): 532.53\n",
      "Estimated Total Size (MB): 771.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5630551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l: list):\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dd75f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03773b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies): \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].plot(train_losses, label='train_losses')\n",
    "    axes[0].plot(valid_losses, label='valid_losses')\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(train_accuracies, label='train_losses')\n",
    "    axes[1].plot(valid_accuracies, label='valid_losses')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac32b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_data, loss_fn):\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(valid_data, leave=False):\n",
    "            X_batch, y_batch = X_batch.to(device).float(), y_batch.to(device).long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "            valid_accuracies.append(((preds == y_batch).sum() / len(preds)).item())\n",
    "    return mean(valid_losses), mean(valid_accuracies)\n",
    "    \n",
    "\n",
    "def train(model, train_data, valid_data, loss_fn, opt, epoches=5):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accuracies, valid_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(train_data, leave=False):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(device).float(), y_batch.to(device).long()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch,)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            train_acc.append(((pred == y_batch).sum() / len(pred)).item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        valid_loss, valid_accuracy = validate(model, valid_data, loss_fn)\n",
    "\n",
    "        train_accuracies.append(mean(train_acc))\n",
    "        train_losses.append(mean(train_loss))\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'epoch: {epoch}: train_loss: {mean(train_losses)}, train_acc: {mean(train_acc)}, val_loss: {valid_loss}, val_acc: {valid_accuracy}')\n",
    "    plot_losses_and_acc(train_losses, train_accuracies, valid_losses, valid_accuracies)\n",
    "    return model, train_losses, train_accuracies, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a26f28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6aa80dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/2 [00:01<?, ?it/s] \u001b[A\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.69 GiB already allocated; 0 bytes free; 3.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, train_losses, train_accuracies, valid_losses, valid_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[60], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, valid_data, loss_fn, opt, epoches)\u001b[0m\n\u001b[0;32m     32\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m     train_acc\u001b[38;5;241m.\u001b[39mappend(((pred \u001b[38;5;241m==\u001b[39m y_batch)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(pred))\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     37\u001b[0m valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m validate(model, valid_data, loss_fn)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.69 GiB already allocated; 0 bytes free; 3.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model, train_losses, train_accuracies, valid_losses, valid_accuracies = train(model, train_loader, test_loader, loss_fn, opt, epoches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ec4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
